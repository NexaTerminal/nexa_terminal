# AI Legal Chatbot - System Architecture & Documentation

**Last Updated:** November 9, 2025
**Status:** Production Ready
**Tech Stack:** MERN + LangChain.js + Qdrant Cloud + OpenAI

---

## Table of Contents

1. [Overview](#overview)
2. [How It Works (User Perspective)](#how-it-works-user-perspective)
3. [System Architecture](#system-architecture)
4. [Technical Components](#technical-components)
5. [Data Flow](#data-flow)
6. [Configuration](#configuration)
7. [Costs & Limits](#costs--limits)
8. [Document Management](#document-management)
9. [Deployment](#deployment)
10. [Troubleshooting](#troubleshooting)

---

## Overview

### What Is It?

The AI Legal Chatbot is a **RAG (Retrieval-Augmented Generation)** system that allows users to ask questions about Macedonian legal documents in natural language. The system:

- Answers questions in **Macedonian language**
- Retrieves relevant information from **546+ legal document chunks**
- Provides **source citations** for transparency
- Limits users to **4 questions per week** (free tier)
- Never uses overly confident language (no "ÑĞ¸Ğ³ÑƒÑ€Ğ½Ğ¾", "Ğ´ĞµÑ„Ğ¸Ğ½Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ğ¾")
- Always asks "Ğ˜Ğ¼Ğ°Ñ‚Ğµ Ğ»Ğ¸ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»Ğ½Ğ¸ Ğ¿Ñ€Ğ°ÑˆĞ°ÑšĞ°?" at the end

### Key Features

âœ… **RAG-Powered Answers** - Combines document retrieval with AI generation
âœ… **Macedonian Language** - Fully supports Cyrillic text
âœ… **Source Citations** - Shows which documents were used
âœ… **Cost-Optimized** - Less than $5/month for 500 documents
âœ… **Production-Grade Vector Search** - Qdrant Cloud HNSW indexing
âœ… **Weekly Limits** - MongoDB-tracked usage quotas

---

## How It Works (User Perspective)

### User Journey

1. **User logs in** to Nexa Terminal
2. **Navigates to** `/terminal/ai-chat`
3. **Sees their question quota** (e.g., "3 / 4 remaining")
4. **Types a question** in Macedonian (max 500 characters):
   - "ĞšĞ¾Ğ¸ ÑĞµ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¸Ñ‚Ğµ ĞµĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¸ Ğ½Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞµĞ½ Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€?"
5. **Waits 2-3 seconds** while the system:
   - Converts question to vector embedding
   - Searches 546 chunks in Qdrant
   - Sends top 5 chunks + question to GPT-4o-mini
   - Gets AI response in Macedonian
6. **Receives answer** with:
   - Main response text
   - List of source documents used
   - "Ğ˜Ğ¼Ğ°Ñ‚Ğµ Ğ»Ğ¸ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»Ğ½Ğ¸ Ğ¿Ñ€Ğ°ÑˆĞ°ÑšĞ°?"
7. **Quota decrements** (3 â†’ 2 remaining)

### What Happens If...

- **User runs out of questions?** â†’ Error message: "ĞˆĞ° Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ½Ğ°Ğ²Ñ‚Ğµ Ğ²Ğ°ÑˆĞ°Ñ‚Ğ° Ğ½ĞµĞ´ĞµĞ»Ğ½Ğ° Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ°"
- **No relevant documents found?** â†’ System responds based on general knowledge (no hallucination)
- **Server/Qdrant is down?** â†’ Error message: "Ğ¡Ğµ ÑĞ»ÑƒÑ‡Ğ¸ Ğ³Ñ€ĞµÑˆĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°..."

---

## System Architecture

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER BROWSER                             â”‚
â”‚                    (React Frontend)                              â”‚
â”‚                  http://localhost:3000/terminal/ai-chat          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â”‚ HTTP POST /api/chatbot/ask
                           â”‚ (JWT Token + Question)
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EXPRESS.JS SERVER                             â”‚
â”‚                  (Node.js Backend - Port 5002)                   â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              ChatBotService.js                            â”‚  â”‚
â”‚  â”‚  1. Check weekly limits (MongoDB)                        â”‚  â”‚
â”‚  â”‚  2. Embed question (OpenAI API)                          â”‚  â”‚
â”‚  â”‚  3. Search vectors (Qdrant Cloud)                        â”‚  â”‚
â”‚  â”‚  4. Format prompt with top 5 chunks                      â”‚  â”‚
â”‚  â”‚  5. Send to GPT-4o-mini (OpenAI API)                     â”‚  â”‚
â”‚  â”‚  6. Return answer + sources                              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”˜
          â”‚                         â”‚                          â”‚
          â”‚                         â”‚                          â”‚
          â–¼                         â–¼                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MongoDB Atlas  â”‚  â”‚   Qdrant Cloud      â”‚  â”‚   OpenAI API         â”‚
â”‚   (Free 512MB)   â”‚  â”‚   (Free 1GB)        â”‚  â”‚   (Pay per use)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ User profiles  â”‚  â”‚ â€¢ 546 vectors       â”‚  â”‚ â€¢ Embeddings         â”‚
â”‚ â€¢ Weekly limits  â”‚  â”‚ â€¢ 1536 dimensions   â”‚  â”‚ â€¢ Chat completions   â”‚
â”‚ â€¢ Doc tracking   â”‚  â”‚ â€¢ Cosine similarity â”‚  â”‚ â€¢ GPT-4o-mini        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tech Stack Breakdown

| Layer | Technology | Purpose |
|-------|------------|---------|
| **Frontend** | React 19 + CSS Modules | Chat interface at `/terminal/ai-chat` |
| **Backend** | Express.js + Node.js | API endpoints + business logic |
| **Vector Database** | Qdrant Cloud (1GB free) | HNSW-indexed similarity search |
| **Document Database** | MongoDB Atlas (512MB free) | User data + usage tracking |
| **AI Model** | GPT-4o-mini (OpenAI) | Answer generation (~$0.15/1M tokens) |
| **Embeddings** | text-embedding-3-small (OpenAI) | Vector embeddings (~$0.02/1M tokens) |
| **RAG Framework** | LangChain.js | Prompt templates + chains |

---

## Technical Components

### 1. Frontend: `client/src/pages/terminal/AIChat.jsx`

**Purpose:** User interface for asking questions

**Key Features:**
- Input field with 500 character limit
- Message history (user questions + AI answers)
- Question counter display (e.g., "3 / 4")
- Error handling with Macedonian messages
- Auto-scroll to latest message

**API Calls:**
```javascript
// Fetch user's remaining questions
GET /api/chatbot/limits
â†’ Returns: { remaining: 3, total: 4, resetDate: "2025-11-11" }

// Ask a question
POST /api/chatbot/ask
Body: { question: "ĞšĞ¾Ğ¸ ÑĞµ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¸Ñ‚Ğµ ĞµĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¸ Ğ½Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞµĞ½ Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€?" }
â†’ Returns: { answer: "...", sources: [...], remainingQuestions: 2 }
```

### 2. Backend: `server/chatbot/ChatBotService.js`

**Purpose:** Core RAG logic

**Main Methods:**

```javascript
class ChatBotService {
  // Called on server startup
  constructor() {
    // Initialize OpenAI chat model (GPT-4o-mini)
    // Initialize OpenAI embeddings (text-embedding-3-small)
    // Initialize Qdrant client
    // Verify Qdrant collection exists
  }

  // Called when user asks a question
  async askQuestion(question, userId) {
    // 1. Check weekly limit (MongoDB)
    // 2. Retrieve top 5 relevant chunks (Qdrant)
    // 3. Format prompt with context
    // 4. Send to GPT-4o-mini
    // 5. Increment usage count (MongoDB)
    // 6. Return answer + sources
  }

  // Searches Qdrant for similar vectors
  async retrieveRelevantDocuments(question) {
    // 1. Embed question using OpenAI (1536 dimensions)
    // 2. Search Qdrant collection (HNSW index)
    // 3. Return top 5 chunks with scores
  }
}
```

**System Prompt Template:**
```
Ğ’Ğ¸Ğµ ÑÑ‚Ğµ Ğ¿Ğ¾Ğ¼Ğ¾ÑˆĞµĞ½ Ğ°ÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ Ğ·Ğ° Ğ¿Ñ€Ğ°Ğ²Ğ½Ğ¸ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸...

Ğ’ĞĞ–ĞĞ˜ ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ Ğ—Ğ ĞšĞĞœĞ£ĞĞ˜ĞšĞĞ¦Ğ˜ĞˆĞ:
- Ğ¡Ğ•ĞšĞĞ“ĞĞ¨ Ğ¾Ğ´Ğ³Ğ¾Ğ²Ğ°Ñ€Ğ°Ñ˜Ñ‚Ğµ Ğ½Ğ° Ğ¼Ğ°ĞºĞµĞ´Ğ¾Ğ½ÑĞºĞ¸ Ñ˜Ğ°Ğ·Ğ¸Ğº
- ĞĞ˜ĞšĞĞ“ĞĞ¨ Ğ½Ğµ ĞºĞ¾Ñ€Ğ¸ÑÑ‚ĞµÑ‚Ğµ Ñ„Ñ€Ğ°Ğ·Ğ¸ ĞºĞ°ĞºĞ¾ "ÑĞ¸Ğ³ÑƒÑ€Ğ½Ğ¾", "Ğ´ĞµÑ„Ğ¸Ğ½Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ğ¾"
- ĞĞ° ĞºÑ€Ğ°Ñ˜Ğ¾Ñ‚ Ğ¾Ğ´ ÑĞµĞºĞ¾Ñ˜ Ğ¾Ğ´Ğ³Ğ¾Ğ²Ğ¾Ñ€, Ğ¿Ñ€Ğ°ÑˆĞ°Ñ˜Ñ‚Ğµ: "Ğ˜Ğ¼Ğ°Ñ‚Ğµ Ğ»Ğ¸ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»Ğ½Ğ¸ Ğ¿Ñ€Ğ°ÑˆĞ°ÑšĞ°?"

ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ¾Ğ´ Ğ¿Ñ€Ğ°Ğ²Ğ½Ğ¸ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¸:
{context}

ĞŸÑ€Ğ°ÑˆĞ°ÑšĞµ Ğ½Ğ° ĞºĞ¾Ñ€Ğ¸ÑĞ½Ğ¸ĞºĞ¾Ñ‚: {question}
```

### 3. Document Processing: `server/scripts/process-documents.js`

**Purpose:** Convert PDF/DOCX files into searchable vector embeddings

**Process:**

```javascript
1. Read files from server/legal sources/
   â”œâ”€ PDF files (uses pdf-parse library)
   â””â”€ DOCX files (uses mammoth library)

2. Extract text (Cyrillic-compatible)
   â†’ Text content from each document

3. Split into chunks
   â”œâ”€ Chunk size: 1000 characters
   â”œâ”€ Overlap: 200 characters
   â””â”€ Uses RecursiveCharacterTextSplitter

4. Create embeddings (OpenAI API)
   â”œâ”€ Model: text-embedding-3-small
   â”œâ”€ Dimensions: 1536
   â””â”€ Cost: ~$0.02 per 1M tokens

5. Upload to Qdrant Cloud
   â”œâ”€ Collection: nexa_legal_docs
   â”œâ”€ Distance: Cosine similarity
   â””â”€ Index: HNSW (fast approximate search)

6. Track in MongoDB
   â””â”€ Collection: chatbot_documents
       (fileName, fileHash, chunkCount, processedAt)
```

**Run Command:**
```bash
cd server
node scripts/process-documents.js
```

**Output:**
```
âœ“ Connected to MongoDB
âœ“ Connected to Qdrant
âœ“ Processed: 13 documents
âœ“ Uploaded 546 vectors to Qdrant
Estimated cost: $0.0021
```

### 4. API Routes: `server/routes/chatbot.js`

**Endpoints:**

```javascript
// Ask a question
POST /api/chatbot/ask
Headers: { Authorization: "Bearer <JWT_TOKEN>" }
Body: { question: "..." }
Response: {
  success: true,
  data: {
    answer: "Ğ¡Ğ¿Ğ¾Ñ€ĞµĞ´ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¸Ñ‚Ğµ...",
    sources: [
      { documentName: "Ğ“Ğ»Ğ°Ğ²Ğ° III.docx", confidence: 0.87, pageNumber: null }
    ],
    timestamp: "2025-11-09T...",
    userId: "...",
    remainingQuestions: 3
  }
}

// Get user's remaining questions
GET /api/chatbot/limits
Headers: { Authorization: "Bearer <JWT_TOKEN>" }
Response: {
  success: true,
  data: {
    remaining: 3,
    total: 4,
    resetDate: "2025-11-11T00:00:00.000Z"
  }
}

// Health check
GET /api/chatbot/health
Response: {
  status: "operational",
  model: "gpt-4o-mini",
  temperature: 0.2,
  vectorStoreInitialized: true
}
```

---

## Data Flow

### Complete Request Flow (User Asks Question)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: USER SUBMITS QUESTION                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ User types: "ĞšĞ¾Ğ¸ ÑĞµ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¸Ñ‚Ğµ ĞµĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¸ Ğ½Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞµĞ½ Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€?"     â”‚
â”‚ Frontend: POST /api/chatbot/ask                                 â”‚
â”‚ Time: 0ms                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: CHECK WEEKLY LIMIT (MongoDB)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Query: db.chatbot_usage.findOne({ userId, weekStart })          â”‚
â”‚ Check: questionsAsked < 4?                                      â”‚
â”‚ Result: Yes (3 < 4) â†’ Continue                                  â”‚
â”‚ Time: 10-50ms                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: CREATE QUERY EMBEDDING (OpenAI API)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ API: POST https://api.openai.com/v1/embeddings                  â”‚
â”‚ Model: text-embedding-3-small                                   â”‚
â”‚ Input: "ĞšĞ¾Ğ¸ ÑĞµ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¸Ñ‚Ğµ ĞµĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¸ Ğ½Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞµĞ½ Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€?"          â”‚
â”‚ Output: [0.123, -0.456, 0.789, ... ] (1536 numbers)            â”‚
â”‚ Cost: ~$0.000002 (negligible)                                   â”‚
â”‚ Time: 100-200ms                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: SEARCH QDRANT FOR SIMILAR VECTORS                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ API: qdrantClient.search("nexa_legal_docs", {                   â”‚
â”‚   vector: [0.123, -0.456, ...],                                 â”‚
â”‚   limit: 5                                                       â”‚
â”‚ })                                                               â”‚
â”‚                                                                   â”‚
â”‚ Qdrant uses HNSW index to find 5 most similar chunks            â”‚
â”‚                                                                   â”‚
â”‚ Results:                                                         â”‚
â”‚ 1. Chunk #45 (score: 0.87) - "Ğ Ğ°Ğ±Ğ¾Ñ‚ĞµĞ½ Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€ ÑĞ¾Ğ´Ñ€Ğ¶Ğ¸..."       â”‚
â”‚ 2. Chunk #123 (score: 0.82) - "ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¸ ĞµĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¸ ÑĞµ..."         â”‚
â”‚ 3. Chunk #267 (score: 0.79) - "Ğ”Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¾Ñ‚ Ğ¼Ğ¾Ñ€Ğ° Ğ´Ğ°..."           â”‚
â”‚ 4. Chunk #89 (score: 0.75) - "Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ¾Ğ´Ğ°Ğ²Ğ°Ñ‡Ğ¾Ñ‚..."                â”‚
â”‚ 5. Chunk #201 (score: 0.71) - "Ğ’Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞµĞ½Ğ¸Ğ¾Ñ‚..."                 â”‚
â”‚                                                                   â”‚
â”‚ Time: 10-20ms (HNSW is FAST!)                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: FORMAT PROMPT WITH CONTEXT                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Combine:                                                         â”‚
â”‚ â€¢ System prompt (rules, tone, language)                         â”‚
â”‚ â€¢ Context from 5 chunks                                          â”‚
â”‚ â€¢ User's question                                                â”‚
â”‚                                                                   â”‚
â”‚ Final prompt sent to GPT:                                        â”‚
â”‚ "Ğ’Ğ¸Ğµ ÑÑ‚Ğµ Ğ¿Ğ¾Ğ¼Ğ¾ÑˆĞµĞ½ Ğ°ÑĞ¸ÑÑ‚ĞµĞ½Ñ‚...                                    â”‚
â”‚  ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚: [Source 1] Ğ“Ğ»Ğ°Ğ²Ğ° III: Ğ Ğ°Ğ±Ğ¾Ñ‚ĞµĞ½ Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€ ÑĞ¾Ğ´Ñ€Ğ¶Ğ¸...     â”‚
â”‚            [Source 2] Ğ“Ğ»Ğ°Ğ²Ğ° II: ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¸ ĞµĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¸ ÑĞµ...          â”‚
â”‚            ...                                                   â”‚
â”‚  ĞŸÑ€Ğ°ÑˆĞ°ÑšĞµ: ĞšĞ¾Ğ¸ ÑĞµ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¸Ñ‚Ğµ ĞµĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¸ Ğ½Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞµĞ½ Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€?"       â”‚
â”‚                                                                   â”‚
â”‚ Time: 1-2ms                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 6: GENERATE ANSWER (OpenAI GPT-4o-mini)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ API: POST https://api.openai.com/v1/chat/completions            â”‚
â”‚ Model: gpt-4o-mini                                               â”‚
â”‚ Temperature: 0.2 (less random, more factual)                    â”‚
â”‚                                                                   â”‚
â”‚ GPT reads context + question â†’ Generates answer in Macedonian   â”‚
â”‚                                                                   â”‚
â”‚ Response:                                                        â”‚
â”‚ "Ğ¡Ğ¿Ğ¾Ñ€ĞµĞ´ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¸Ñ‚Ğµ, Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¸Ñ‚Ğµ ĞµĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¸ Ğ½Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞµĞ½ Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€      â”‚
â”‚  Ğ²ĞºĞ»ÑƒÑ‡ÑƒĞ²Ğ°Ğ°Ñ‚: Ğ¸Ğ¼Ğµ Ğ¸ Ğ¿Ñ€ĞµĞ·Ğ¸Ğ¼Ğµ Ğ½Ğ° Ğ²Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞµĞ½Ğ¸Ğ¾Ñ‚, Ğ¿Ğ¾Ğ´Ğ°Ñ‚Ğ¾Ñ†Ğ¸ Ğ·Ğ°          â”‚
â”‚  Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ¾Ğ´Ğ°Ğ²Ğ°Ñ‡Ğ¾Ñ‚, Ğ¾Ğ¿Ğ¸Ñ Ğ½Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ½Ğ¾Ñ‚Ğ¾ Ğ¼ĞµÑÑ‚Ğ¾, Ğ²Ğ¸ÑĞ¸Ğ½Ğ° Ğ½Ğ° Ğ¿Ğ»Ğ°Ñ‚Ğ°Ñ‚Ğ°...   â”‚
â”‚  Ğ˜Ğ¼Ğ°Ñ‚Ğµ Ğ»Ğ¸ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»Ğ½Ğ¸ Ğ¿Ñ€Ğ°ÑˆĞ°ÑšĞ°?"                                â”‚
â”‚                                                                   â”‚
â”‚ Cost: ~$0.0001 per question                                      â”‚
â”‚ Time: 1-2 seconds                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 7: INCREMENT USAGE COUNT (MongoDB)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Update: db.chatbot_usage.updateOne(                             â”‚
â”‚   { userId, weekStart },                                         â”‚
â”‚   { $inc: { questionsAsked: 1 } }                               â”‚
â”‚ )                                                                â”‚
â”‚                                                                   â”‚
â”‚ questionsAsked: 3 â†’ 4                                            â”‚
â”‚ remaining: 4 - 4 = 0                                             â”‚
â”‚                                                                   â”‚
â”‚ Time: 10-50ms                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 8: RETURN RESPONSE TO USER                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ JSON Response:                                                   â”‚
â”‚ {                                                                â”‚
â”‚   success: true,                                                 â”‚
â”‚   data: {                                                        â”‚
â”‚     answer: "Ğ¡Ğ¿Ğ¾Ñ€ĞµĞ´ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¸Ñ‚Ğµ...",                            â”‚
â”‚     sources: [                                                   â”‚
â”‚       { documentName: "Ğ“Ğ»Ğ°Ğ²Ğ° III.docx", confidence: 0.87 }      â”‚
â”‚     ],                                                           â”‚
â”‚     remainingQuestions: 0                                        â”‚
â”‚   }                                                              â”‚
â”‚ }                                                                â”‚
â”‚                                                                   â”‚
â”‚ Frontend displays answer + updates counter (4/4 â†’ 0/4)          â”‚
â”‚                                                                   â”‚
â”‚ TOTAL TIME: ~2-3 seconds                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Configuration

### Environment Variables

**Required in `.env.development` and production `.env`:**

```bash
# OpenAI Configuration
OPENAI_API_KEY=sk-proj-...
OPENAI_MODEL=gpt-4o-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# AI Chatbot Settings
CHATBOT_MAX_PROMPTS_PER_WEEK=4
CHATBOT_TEMPERATURE=0.2

# Qdrant Cloud Configuration
QDRANT_URL=https://0e2686c0-8c77-46df-847e-5f7d6012fe3e.europe-west3-0.gcp.cloud.qdrant.io:6333
QDRANT_API_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
QDRANT_COLLECTION_NAME=nexa_legal_docs

# MongoDB (for usage tracking)
MONGODB_URI=mongodb+srv://...
```

### Feature Toggle

**In `server/config/settingsManager.js`:**

```javascript
features: {
  aiChatbot: true  // Enable/disable entire chatbot feature
}
```

**In `server/server.js`:**

```javascript
if (settings.isFeatureEnabled('aiChatbot')) {
  const chatBotService = require('./chatbot/ChatBotService');
  await chatBotService.setDatabase(database);
}
```

### MongoDB Collections

The chatbot uses 3 MongoDB collections:

```javascript
// 1. Usage tracking (weekly limits)
chatbot_usage: {
  userId: ObjectId,
  weekStart: Date,           // Monday 00:00:00
  questionsAsked: Number,    // 0-4
  lastAskedAt: Date,
  createdAt: Date
}

// 2. Document processing status
chatbot_documents: {
  fileName: String,
  fileHash: String,          // MD5 hash for change detection
  filePath: String,
  pageCount: Number,
  chunkCount: Number,
  textLength: Number,
  processedAt: Date,
  status: String             // "processed"
}

// 3. Conversation history (future feature - not implemented yet)
chatbot_conversations: {
  userId: ObjectId,
  question: String,
  answer: String,
  sources: Array,
  timestamp: Date
}
```

---

## Costs & Limits

### OpenAI Costs (Pay-per-use)

| Operation | Model | Cost | Usage |
|-----------|-------|------|-------|
| **Embedding** (query) | text-embedding-3-small | $0.02 / 1M tokens | ~$0.000002 per question |
| **Chat Completion** | gpt-4o-mini | $0.15 / 1M input tokens<br>$0.60 / 1M output tokens | ~$0.0001 per question |

**Monthly Cost Estimate:**
- 1000 users Ã— 4 questions/week = 16,000 questions/month
- Cost: ~$1.60/month

### Qdrant Cloud (Free Tier)

- **Free tier:** 1GB cluster
- **Current usage:** 546 vectors Ã— ~6KB = ~3.3MB
- **Capacity:** Can handle ~150,000 vectors (500+ documents)
- **Queries:** Unlimited
- **Cost:** $0/month (free forever)

### MongoDB Atlas (Free Tier)

- **Free tier:** 512MB storage
- **Current usage:** ~2MB (user data + usage tracking)
- **Capacity:** ~200,000 users with 4 questions/week
- **Cost:** $0/month (free forever)

### Total Monthly Cost

| Scenario | Users | Questions/Month | Cost |
|----------|-------|-----------------|------|
| **Current** | 10 | 160 | ~$0.02 |
| **Small scale** | 100 | 1,600 | ~$0.16 |
| **Medium scale** | 1,000 | 16,000 | ~$1.60 |
| **Large scale** | 10,000 | 160,000 | ~$16.00 |

**Note:** All costs are for OpenAI only. Qdrant and MongoDB are free.

---

## Document Management

### Adding New Documents

**Option 1: Add to Existing Collection**

```bash
# 1. Copy new document to legal sources folder
cp "New_Law.docx" server/legal\ sources/

# 2. Reprocess all documents (detects new file)
cd server
node scripts/process-documents.js

# Expected output:
# âœ“ Processed: 1 new document (New_Law.docx)
# âœ“ Skipped: 13 unchanged documents
# âœ“ Uploaded 37 new vectors to Qdrant (total: 583)
```

**Option 2: Replace Existing Document (Law Changed)**

```bash
# 1. Replace file with same name
cp "Updated_Ğ—Ğ°ĞºĞ¾Ğ½_Ğ·Ğ°_Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ½Ğ¸_Ğ¾Ğ´Ğ½Ğ¾ÑĞ¸.docx" "server/legal sources/Ğ—Ğ°ĞºĞ¾Ğ½ Ğ·Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ½Ğ¸ Ğ¾Ğ´Ğ½Ğ¾ÑĞ¸.docx"

# 2. Clear tracking to force reprocessing
node -e "
const { MongoClient } = require('mongodb');
require('dotenv').config({ path: './.env.development' });
(async () => {
  const client = new MongoClient(process.env.MONGODB_URI);
  await client.connect();
  const db = client.db();
  await db.collection('chatbot_documents').deleteMany({ fileName: 'Ğ—Ğ°ĞºĞ¾Ğ½ Ğ·Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ½Ğ¸ Ğ¾Ğ´Ğ½Ğ¾ÑĞ¸.docx' });
  console.log('Cleared tracking for updated document');
  await client.close();
})();
"

# 3. Reprocess
node scripts/process-documents.js

# Expected output:
# âœ“ Processed: 1 updated document
# ğŸ—‘ï¸ Cleared old vectors from Qdrant
# âœ“ Created fresh collection
# âœ“ Uploaded 546 vectors (replaced all)
```

### Removing Documents

```bash
# 1. Delete file from legal sources
rm "server/legal sources/Old_Law.docx"

# 2. Reprocess (will detect missing file)
node scripts/process-documents.js

# Note: Currently recreates entire collection.
# Future: Granular delete by document name
```

### Checking What's Indexed

```bash
# Query Qdrant Cloud dashboard
# OR use Qdrant API:
curl -X GET "https://your-qdrant-url:6333/collections/nexa_legal_docs" \
  -H "api-key: your-api-key"

# Response:
{
  "result": {
    "points_count": 546,
    "vectors_count": 546,
    "indexed_vectors_count": 546
  }
}
```

---

## Deployment

### Local Development

```bash
# 1. Install dependencies
cd server && npm install
cd client && npm install

# 2. Configure environment
cp server/.env.example server/.env.development
# Add OpenAI, Qdrant, MongoDB credentials

# 3. Process documents (one-time setup)
cd server
node scripts/process-documents.js

# 4. Start servers
npm run dev              # Backend (port 5002)
cd ../client && npm start  # Frontend (port 3000)
```

### Production Deployment

**Backend (Render/Railway):**

```bash
# 1. Set environment variables in Render dashboard:
OPENAI_API_KEY=...
OPENAI_MODEL=gpt-4o-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
CHATBOT_MAX_PROMPTS_PER_WEEK=4
CHATBOT_TEMPERATURE=0.2
QDRANT_URL=...
QDRANT_API_KEY=...
QDRANT_COLLECTION_NAME=nexa_legal_docs
MONGODB_URI=...
NODE_ENV=production

# 2. Deploy code (auto-deploy from GitHub)
git push origin main

# 3. One-time: Process documents on server
# SSH into server OR add to build command:
node scripts/process-documents.js

# 4. Server starts automatically
npm start
```

**Frontend (Vercel):**

```bash
# 1. Connect GitHub repo to Vercel
# 2. Configure build settings:
Build Command: npm run build
Output Directory: build
Install Command: npm install

# 3. Deploy automatically on git push
```

### Important Deployment Notes

- **Qdrant vectors persist** - No need to reprocess on every deploy
- **MongoDB tracks processed docs** - Incremental updates work
- **Environment variables** must match between local and production
- **First deploy:** Run `process-documents.js` once manually
- **Updates:** Only reprocess when documents change

---

## Troubleshooting

### Issue: "Vector store not initialized"

**Symptoms:**
```
âš ï¸ Vector store not initialized. Using placeholder context.
```

**Cause:** Qdrant collection doesn't exist or is empty

**Fix:**
```bash
cd server
node scripts/process-documents.js
# Restart server
```

### Issue: "ĞˆĞ° Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ½Ğ°Ğ²Ñ‚Ğµ Ğ²Ğ°ÑˆĞ°Ñ‚Ğ° Ğ½ĞµĞ´ĞµĞ»Ğ½Ğ° Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ°"

**Symptoms:** User can't ask questions even though week has passed

**Cause:** Week calculation uses Monday 00:00:00 as reset point

**Fix:**
```javascript
// Check current week start
const now = new Date();
const dayOfWeek = now.getDay(); // 0 = Sunday
const daysToMonday = dayOfWeek === 0 ? 6 : dayOfWeek - 1;
const weekStart = new Date(now);
weekStart.setDate(now.getDate() - daysToMonday);
weekStart.setHours(0, 0, 0, 0);
console.log('Week starts:', weekStart);

// Manually reset user if needed
db.chatbot_usage.deleteMany({ userId: "user_id_here" });
```

### Issue: Slow responses (>5 seconds)

**Symptoms:** Users complain about long wait times

**Possible Causes:**
1. **Too many chunks** â†’ Reduce `limit: 5` in Qdrant search to `limit: 3`
2. **OpenAI rate limits** â†’ Check OpenAI dashboard for throttling
3. **Qdrant timeout** â†’ Check Qdrant Cloud status
4. **Large documents** â†’ Reduce chunk size from 1000 to 500 chars

**Debug:**
```javascript
// Add timing logs in ChatBotService.js
console.time('embedding');
const questionEmbedding = await this.embeddings.embedQuery(question);
console.timeEnd('embedding');

console.time('qdrant_search');
const searchResult = await this.qdrantClient.search(...);
console.timeEnd('qdrant_search');

console.time('gpt_response');
const response = await chain.invoke(...);
console.timeEnd('gpt_response');
```

### Issue: PDF processing fails

**Symptoms:**
```
âŒ Error processing document.pdf: pdf is not a function
```

**Cause:** `pdf-parse` library issue (known bug)

**Current workaround:** Convert PDFs to DOCX using:
- https://pdf2docx.com/
- Adobe Acrobat
- Microsoft Word

**Future fix:** Switch to different PDF library (e.g., `@llama-index/readers`)

### Issue: Macedonian text appears as ï¿½ï¿½ï¿½ï¿½ï¿½

**Symptoms:** Cyrillic characters corrupted in responses

**Cause:** Encoding issue with document processing

**Fix:**
1. Ensure documents are saved in **UTF-8**
2. Check `mammoth` options:
```javascript
const result = await mammoth.extractRawText({
  path: filePath,
  encoding: 'utf-8'  // Explicitly set UTF-8
});
```

---

## Summary

### What You Have Now

âœ… Production-ready RAG chatbot
âœ… 546 legal document chunks indexed in Qdrant
âœ… Macedonian language support
âœ… Weekly usage limits (4 questions/user)
âœ… Source citations
âœ… Cost: ~$0.0001 per question
âœ… Free infrastructure (Qdrant + MongoDB)
âœ… Scalable to 500+ documents

### Key Files

```
server/
â”œâ”€â”€ chatbot/
â”‚   â””â”€â”€ ChatBotService.js          # Core RAG logic
â”œâ”€â”€ routes/
â”‚   â””â”€â”€ chatbot.js                 # API endpoints
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ process-documents.js       # Document â†’ Vectors
â””â”€â”€ legal sources/                 # Source documents (PDFs/DOCX)

client/
â””â”€â”€ src/
    â””â”€â”€ pages/terminal/
        â””â”€â”€ AIChat.jsx             # Chat interface
```

### Next Steps (Future Enhancements)

1. **Conversation History** - Store past Q&A in MongoDB
2. **PDF Support** - Fix pdf-parse or switch library
3. **Granular Updates** - Update single document without reprocessing all
4. **Feedback Loop** - "Was this helpful?" ratings
5. **Advanced Search** - Filter by document type, date, etc.
6. **Streaming Responses** - Real-time answer generation (like ChatGPT)

---

**Documentation maintained by:** Claude Code
**Questions?** Check server logs or contact: terminalnexa@gmail.com
